---
sidebar_position: 5
---

# AWQ for Low-Precision Inference

AWQ is a 4-bit inference technique designed for LLMs to reduce memory usage and computational requirements during the inference process without significantly compromising model quality.

For more information on AWQ and its usage with FastChat, refer to [AWQ official documentation](https://awq-project.io/docs).
